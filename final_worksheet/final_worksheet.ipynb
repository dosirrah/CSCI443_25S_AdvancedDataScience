{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad4c830d-32c9-48c4-9ad1-f838d0e499ff",
   "metadata": {},
   "source": [
    "## Final Review Worksheet\n",
    "\n",
    "The final is comprehensive.\n",
    "\n",
    "This covers sample questions from the topics that will be covered.\n",
    "\n",
    "Data Engineering:\n",
    "\n",
    " * why Numpy is faster than Python without Numpy see lecture 2)\n",
    "   -  why are vector operations important? \n",
    " * differences between Pandas and Spark (see lecture 3)\n",
    " * Spark Dataframes, RDDs, lazy evaluation (see lectures 5, 6, 8, abd 9)\n",
    " * Types of transformations (narrow and wide)\n",
    " * Different kinds of storage.\n",
    "   - What are the tradeoffs?\n",
    "   - Why do we need Blob storage (e.g., S3)?\n",
    " * What is ETL?   (see lecture 18)\n",
    " * What is EC2?\n",
    " * What is Kakfa?  (see lecture 20)\n",
    " * What are the differences between batch and stream processing (see lecture 19)\n",
    "\n",
    "Statistics:\n",
    "\n",
    " * Types of error  (see lecture 4)\n",
    " * Populations vs. Samples (see lectures 7)\n",
    " * Sampling distributions (see lecture 10)\n",
    " * Confidence Intervals (see lecture 11)\n",
    " * Significance Levels and hypothesis testing (see lectures 12 and 13)\n",
    " * Bootstrapping\n",
    " * Permutation Tests\n",
    " * ANOVA\n",
    " * Chi-square\n",
    "\n",
    "The above is just a list of broad topics.  The sample questions in this\n",
    "review should guide you as to what kinds of questions will appear on the\n",
    "final."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596f1577-ad87-4e68-93ee-899dbb997fe1",
   "metadata": {},
   "source": [
    "## Part @P:D. Types of data\n",
    "\n",
    "Which of the following data types is numeric, and which is\n",
    "categorical? For the categorical data, specify if it is nominal or\n",
    "ordinal.\n",
    "\n",
    "**@D1.** A person’s blood type (A, B, AB, O) is an example of:\n",
    "\n",
    "* (A) Categorical Ordinal\n",
    "* (B) Categorical Nominal ☑️\n",
    "* (C) Numeric\n",
    "\n",
    "Answer: B\n",
    "\n",
    "**@D2.** The number of siblings a person has is an example of:\n",
    "\n",
    "* (A) Categorical Ordinal\n",
    "* (B) Categorical Nominal\n",
    "* (C) Numeric ☑️\n",
    "\n",
    "Answer: C\n",
    "\n",
    "**@D3.** T-shirt sizes (Small, Medium, Large) are an example of:\n",
    "\n",
    "* (A) Categorical Ordinal ☑️\n",
    "* (B) Categorical Nominal\n",
    "* (C) Numeric\n",
    "\n",
    "Answer: A\n",
    "\n",
    "\n",
    "**@D4.** Eye color (blue, green, brown) is an example of:\n",
    "\n",
    "* (A) Categorical Ordinal\n",
    "* (B) Categorical Nominal ☑️\n",
    "* (C) Numeric\n",
    "\n",
    "Answer: B\n",
    "\n",
    "\n",
    "**@D5.** A movie’s star rating (1 star to 5 stars) is an example of:\n",
    "\n",
    "* (A) Categorical Ordinal ☑️\n",
    "* (B) Categorical Nominal\n",
    "* (C) Numeric\n",
    "\n",
    "Answer: A\n",
    "\n",
    "\n",
    "**@D6.** A student’s ID number is an example of:\n",
    "\n",
    "* (A) Categorical Ordinal\n",
    "* (B) Categorical Nominal ☑️\n",
    "* (C) Numeric\n",
    "\n",
    "Answer: B\n",
    "(Even though it looks like a number, the ID number is a label, not a measurable quantity.)\n",
    "\n",
    "\n",
    "**@D7.** A runner’s race time in minutes is an example of:\n",
    "\n",
    "* (A) Categorical Ordinal\n",
    "* (B) Categorical Nominal\n",
    "* (C) Numeric ☑️\n",
    "\n",
    "Answer: C\n",
    "\n",
    "\n",
    "**@D8.** The brand of smartphone someone owns (Apple, Samsung, Google) is an example of:\n",
    "\n",
    "* (A) Categorical Ordinal\n",
    "* (B) Categorical Nominal ☑️\n",
    "* (C) Numeric\n",
    "\n",
    "Answer: B\n",
    "\n",
    "\n",
    "**@D9.** Pain intensity measured as “Mild, Moderate, Severe” is an example of:\n",
    "\n",
    "* (A) Categorical Ordinal ☑️\n",
    "* (B) Categorical Nominal\n",
    "* (C) Numeric\n",
    "\n",
    "Answer: A\n",
    "\n",
    "\n",
    "**@D10.** The temperature in degrees Fahrenheit is an example of:\n",
    "\n",
    "* (A) Categorical Ordinal\n",
    "* (B) Categorical Nominal\n",
    "* (C) Numeric ☑️\n",
    "\n",
    "Answer: C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7be01e8-21c4-4082-9c95-3c9623249102",
   "metadata": {},
   "source": [
    "## Part @P:MCS. Multiple Choice Statistics\n",
    "\n",
    "**@MS1.** Which measure is most sensitive to outliers in a dataset?\n",
    "\n",
    "* (A) Median\n",
    "* (B) Mode\n",
    "* (C) Mean ☑️\n",
    "* (D) Quartiles\n",
    "\n",
    "Answer: C\n",
    "\n",
    "Discussion: Median discards all numbers except the middle one.  Outliers\n",
    "have no effect on the median.  The mode is the most frequent sample. Quartiles\n",
    "may discoard all values other than the middle, but moving the 25th percentile\n",
    "would require changing the distribution of samples all the way up to and\n",
    "INCLUDING the 25th percentile.  Analogously moving the 75th percentile would\n",
    "require changing the distribution of samples including and above the 75th \n",
    "percentile.   If we define outliers as being 1.5 IQR above the 3rd quartile\n",
    "or 1.5 IQR below the 1st quartile then the it is impossible for the movement\n",
    "of outliers to affect quartiles.\n",
    "\n",
    "**@MS2.** If your data is heavily skewed, the best measure of central tendency is:\n",
    "\n",
    "* (A) Median ☑️\n",
    "* (B) Mean\n",
    "* (C) Variance\n",
    "* (D) Mode\n",
    "\n",
    "Answer: A\n",
    "\n",
    "**@MS3.** The variance of a dataset describes:\n",
    "\n",
    "* (A) The midpoint of the data\n",
    "* (B) The average absolute deviation from the mean\n",
    "* (C) The average squared deviation from the mean ☑️\n",
    "* (D) The most frequent value\n",
    "\n",
    "Answer: C\n",
    "\n",
    "**@MS4.** The probability of two independent events occurring simultaneously is found by:\n",
    "\n",
    "* (A) Summing their probabilities\n",
    "* (B) Multiplying their probabilities ☑️\n",
    "* (C) Subtracting probabilities\n",
    "* (D) Dividing probabilities\n",
    "\n",
    "Answer: B\n",
    "\n",
    "**@MS5.** Under which condition is the Central Limit Theorem most reliably applicable, \n",
    "ensuring that the sampling distribution of the mean approaches normality?\n",
    "\n",
    "* (A) When sample size is sufficiently large, the population distribution is symmetric, and \n",
    "the mean and variance are infinite\n",
    "* (B) When observations are dependent but identically distributed\n",
    "* (C) When the population distribution is heavily skewed and the sample size is very small\n",
    "* (D) When sample size is sufficiently large and observations are independent, even if the original distribution is not normal ☑️\n",
    "\n",
    "Answer: D\n",
    "\n",
    "**@MS6.** Rejecting a true null hypothesis is called a:\n",
    "\n",
    "* (A) Type II error\n",
    "* (B) Type I error ☑️\n",
    "* (C) Sampling error\n",
    "* (D) Standard error\n",
    "\n",
    "Answer: B\n",
    "\n",
    "Type I errors are false positives.  If we reject a null hypothesis this means that\n",
    "we \n",
    "\n",
    "**@MS7.** A test statistic measures:\n",
    "\n",
    "* (A) The accuracy of the alternate hypothesis\n",
    "* (B) The probability of the alternative hypothesis given the observations\n",
    "* (C) How far data deviates from the expected under the null hypothesis ☑️\n",
    "* (D) The correlation between samples of two random variables\n",
    "\n",
    "Answer: C\n",
    "\n",
    "**@MS8.** The Normal distribution is characterized by:\n",
    "\n",
    "* (A) Mean and standard deviation ☑️\n",
    "* (B) Mode and range\n",
    "* (C) Median and IQR\n",
    "* (D) Mean only\n",
    "\n",
    "Answer: A\n",
    "\n",
    "**@MS9.** Which distribution is ideal for modeling waiting times or intervals between independent events?\n",
    "\n",
    "* (A) Uniform distribution\n",
    "* (B) Binomial distribution\n",
    "* (C) Normal distribution\n",
    "* (D) Exponential distribution ☑️\n",
    "\n",
    "Answer: D\n",
    "\n",
    "**@MS10.** Which of the following will NOT typically narrow a confidence interval?\n",
    "\n",
    "* (A) Increasing the sample size\n",
    "* (B) Decreasing the confidence level\n",
    "* (C) Increasing the sample variability ☑️\n",
    "* (D) Using a t-distribution instead of a z-distribution for small samples\n",
    "\n",
    "Answer: C\n",
    "\n",
    "**@MS11.** Which scenario is most appropriate for a binomial test?\n",
    "\n",
    "* (A) Testing whether a coin is fair after 100 flips ☑️\n",
    "* (B) Comparing the means of three treatments\n",
    "* (C) Analyzing the variance in test scores\n",
    "* (D) Estimating the slope of a regression line\n",
    "\n",
    "Answer: A\n",
    "\n",
    "**@MS12.** The purpose of ANOVA is to:\n",
    "\n",
    "* (A) Estimate the confidence interval for the mean of one group\n",
    "* (B) Test whether three or more group means differ significantly ☑️\n",
    "* (C) Test the relationship between two variables\n",
    "* (D) Compare variances across all observations\n",
    "\n",
    "Answer: B\n",
    "\n",
    "**@MS13.** How does permutation ANOVA differ from classical ANOVA?\n",
    "\n",
    "* (A) It compares group medians instead of means\n",
    "* (B) It builds the null distribution by randomly reassigning group labels ☑️\n",
    "* (C) It assumes equal group variances but not normality\n",
    "* (D) It replaces F-statistics with rank-based calculations\n",
    "\n",
    "Answer: B\n",
    "\n",
    "**@MS14.** What does a Chi-Squared goodness-of-fit test evaluate?\n",
    "\n",
    "* (A) Whether two numeric variables are linearly related\n",
    "* (B) Whether observed sample proportions differ from those in another sample\n",
    "* (C) Whether observed frequencies differ from expected frequencies under a specified distribution ☑️\n",
    "* (D) Whether the average value differs significantly across categories\n",
    "\n",
    "Answer: C\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f686d44-4ec8-4fa8-be19-09f165954e63",
   "metadata": {},
   "source": [
    "## Multiple choice Data Engineering\n",
    "\n",
    "**@MP1.** Why is NumPy generally faster than standard Python for numerical operations?\n",
    "\n",
    "* (A) It uses Python loops internally\n",
    "* (B) It stores data in dictionaries\n",
    "* (C) It operates on compiled C arrays using vectorization\n",
    "* (D) It avoids using memory\n",
    "\n",
    "Answer: C\n",
    "\n",
    "**@MP2.** What is a primary reason to use vector operations in NumPy?\n",
    "\n",
    "* (A) They save RAM\n",
    "* (B) They reduce precision\n",
    "* (C) Vector operations in NumPy use GPUs for acceleration.\n",
    "* (D) They leverage CPU-level parallelism and avoid Python-level loops\n",
    "\n",
    "Answer: D\n",
    "\n",
    "**@MP3.** In contrast to Python lists, NumPy arrays are:\n",
    "\n",
    "* (A) Homogeneous and stored in contiguous memory\n",
    "* (B) Heterogeneous\n",
    "* (C) Stored as trees\n",
    "* (D) Immutable\n",
    "\n",
    "Answer: A\n",
    "\n",
    "**@MP4.** Pandas DataFrames are better suited for:\n",
    "\n",
    "* (A) Distributed computing across multiple nodes\n",
    "* (B) In-memory computations on small to medium datasets\n",
    "* (C) Real-time data ingestion\n",
    "* (D) Event-based systems\n",
    "\n",
    "Answer: C\n",
    "\n",
    "**@MP5.** Spark DataFrames are built on top of:\n",
    "\n",
    "* (A) JSON\n",
    "* (B) RDDs\n",
    "* (C) SQLAlchemy\n",
    "* (D) NumPy\n",
    "\n",
    "Answer: B\n",
    "\n",
    "**@MP6.** Spark uses lazy evaluation. What does that mean?\n",
    "\n",
    "* (A) It runs all computations immediately\n",
    "* (B) It builds a DAG and waits to execute until an action is called\n",
    "* (C) It compiles jobs into Python bytecode\n",
    "* (D) It randomly delays transformations\n",
    "\n",
    "Answer: B\n",
    "\n",
    "**@MP7.** An RDD in Spark is best described as:\n",
    "\n",
    "* (A) A dataframe in Pandas\n",
    "* (B) A type of JSON file\n",
    "* (C) A distributed, immutable collection of objects\n",
    "* (D) A database table\n",
    "\n",
    "Answer: C\n",
    "\n",
    "**@MP8.** A narrow transformation in Spark:\n",
    "\n",
    "* (A) Requires shuffling data across nodes\n",
    "* (B) Depends on multiple partitions\n",
    "* (C) Transforms rows without reordering rows.\n",
    "* (D) Has all output partitions derived from a single input partition\n",
    "\n",
    "Answer: D\n",
    "\n",
    "**@MP9.** Which transformation can cause a shuffle in Spark?\n",
    "\n",
    "* (A) join()\n",
    "* (B) map()\n",
    "* (C) filter()\n",
    "* (D) count()\n",
    "\n",
    "Answer: A\n",
    "\n",
    "**@MP10.** Which of the following is a benefit of Parquet over CSV?\n",
    "\n",
    "* (A) Easier to edit by hand\n",
    "* (B) Better for storing images\n",
    "* (C) It cannot be used with Spark\n",
    "* (D) Columnar format allows for better compression and faster queries\n",
    "\n",
    "Answer: D\n",
    "\n",
    "**@MP11.** Blob storage refers to:\n",
    "\n",
    "* (A) A relational database engine\n",
    "* (B) A streaming buffer\n",
    "* (C) Storage for unstructured data like files and videos\n",
    "* (D) Storage used only for machine learning models\n",
    "\n",
    "Answer: C\n",
    "\n",
    "**@MP12.** In an ETL pipeline, the “Transform” step typically involves:\n",
    "\n",
    "* (A) Extracting files from S3\n",
    "* (B) Writing data to a blob store\n",
    "* (C) Cleaning and formatting data for analytics\n",
    "* (D) Uploading files manually\n",
    "\n",
    "Answer: C\n",
    "\n",
    "**@MP13.** EC2 is a service provided by:\n",
    "\n",
    "* (A) Google\n",
    "* (B) AWS\n",
    "* (C) Databricks\n",
    "* (D) Spark\n",
    "\n",
    "Answer: B\n",
    "\n",
    "**@MP14.** EC2 allows you to:\n",
    "\n",
    "* (A) Store structured data\n",
    "* (B) Run SQL queries\n",
    "* (C) Launch virtual machines\n",
    "* (D) Stream data in real time\n",
    "\n",
    "Answer: C\n",
    "\n",
    "**@MP15.** In stream processing, windowing is used to:\n",
    "\n",
    "* (A) Split large CSVs\n",
    "* (B) Join static and dynamic tables\n",
    "* (C) Convolve a function with local support over data \n",
    "* (D) Aggregate data over specific time intervals\n",
    "\n",
    "Answer: D\n",
    "\n",
    "**@MP16.** Kafka is primarily used for:\n",
    "\n",
    "* (A) Real-time message streaming\n",
    "* (B) In-memory computation\n",
    "* (C) Long-term data archival\n",
    "* (D) Efficient SQL database batch querying\n",
    "\n",
    "Answer: A\n",
    "\n",
    "**@MP17.** What are Kafka consumers responsible for?\n",
    "\n",
    "* (A) Writing data to storage\n",
    "* (B) Reading messages from topics\n",
    "* (C) Writing messages to a Kafka topic\n",
    "* (D) Running SQL queries\n",
    "\n",
    "Answer: B\n",
    "\n",
    "**@MP18.** Kafka is most often used in conjunction with:\n",
    "\n",
    "* (A) NoSQL databases exclusively\n",
    "* (B) Excel or other spreadsheet software\n",
    "* (C) REST APIs\n",
    "* (D) Stream processing engines\n",
    "\n",
    "Answer: D\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9f0478-a1a6-4a95-826e-1dcb25b0fd2f",
   "metadata": {},
   "source": [
    "## Part @P:Bias. Bias and Error\n",
    "\n",
    "For each scenario, identify the **type(s) of error** present and **explain your reasoning**. Consider\n",
    "both **random error** and **systematic bias**. If multiple types of bias apply, explain why. \n",
    "\n",
    "\n",
    "Types of bias/errors to consider:\n",
    "\n",
    "* Attrition bias\n",
    "* Convenience sampling bias\n",
    "* Exclusion bias\n",
    "* Measurement bias\n",
    "* Non-response bias\n",
    "* Observer bias\n",
    "* Random measurement error\n",
    "* Self-reporting bias\n",
    "* Self-selection bias\n",
    "* Social desirability bias\n",
    "* Survivorship bias\n",
    "* Undercoverage bias\n",
    "\n",
    "\n",
    "**@B1.** A fitness center surveys its customers about satisfaction with \n",
    "personal training services. Surveys are only given to customers who have purchased at least 10 sessions.\n",
    "\n",
    "**Answer**: Convenience Sampling Bias\n",
    "\n",
    "**Explanation**:\n",
    "The survey only includes customers who have already purchased 10 sessions—likely more engaged or satisfied customers. This convenience sampling excludes less committed or less satisfied customers, biasing results.\n",
    "\n",
    "\n",
    "\n",
    "**@B2.** During a large epidemiological study, researchers send out paper\n",
    "questionnaires by mail. Many young adults fail to respond.\n",
    "\n",
    "**Answer**: Non-Response Bias\n",
    "\n",
    "Explanation:\n",
    "Young adults are underrepresented because they fail to return the paper survey.\n",
    "The respondents differ systematically from non-respondents, introducing non-response bias.\n",
    "\n",
    "\n",
    "**@B3.** A lab technician calibrates a new thermometer incorrectly, causing it\n",
    "to consistently read 2 degrees lower than the true temperature.\n",
    "\n",
    "**Answer**: Measurement Bias\n",
    "\n",
    "Explanation:\n",
    "The thermometer consistently underreports temperatures by 2 degrees. This is systematic\n",
    "measurement error, making all measurements biased in the same direction—measurement bias.\n",
    "\n",
    "\n",
    "**@B4.** A marketing study collects feedback only from users of a new product\n",
    "who voluntarily joined an online fan group.\n",
    "\n",
    "**Answer**: Self-Selection Bias\n",
    "\n",
    "**Explanation**:\n",
    "Only fans who chose to join the group respond. These individuals are likely more positive\n",
    "toward the product, meaning their feedback is not representative of all customers.\n",
    "Self-selection bias is present.\n",
    "\n",
    "\n",
    "**@B5.** A university study compares study habits across disciplines. However,\n",
    "they randomly sample students but forget to include night school students, who\n",
    "make up 20% of the population.\n",
    "\n",
    "**Answer** Undercoverage Bias\n",
    "\n",
    "**Explanation**:\n",
    "Night school students, a significant group, were left out unintentionally. When an\n",
    "important subpopulation is not adequately represented, it’s called undercoverage bias.\n",
    "\n",
    "\n",
    "**@B6.** Participants in a psychological study are asked to estimate their alcohol\n",
    "consumption during the past month.\n",
    "\n",
    "**Answer**: Self-Reporting Bias\n",
    "\n",
    "**Explanation**:\n",
    "Participants must recall and report their own behavior (alcohol consumption),\n",
    "leading to potential inaccuracies, exaggeration, or underreporting—classic\n",
    "self-reporting bias.\n",
    "\n",
    "\n",
    "**@B7.** A job interview study records applicant evaluations. Interviewers know which\n",
    "applicants came from prestigious universities and tend to rate those applicants higher,\n",
    "even if their interview performance is similar.\n",
    "\n",
    "**Answer**: Observer Bias\n",
    "\n",
    "**Explanation**:\n",
    "Interviewers know the applicants’ backgrounds and subconsciously rate prestigious \n",
    "university candidates higher, independent of actual performance. This is observer bias.\n",
    "\n",
    "\n",
    "**@B8.** A longitudinal study on exercise habits reports outstanding long-term results.\n",
    "However, only participants who completed all 5 years are included in the published analysis.\n",
    "\n",
    "**Answer**: Survivorship Bias\n",
    "\n",
    "Explanation:\n",
    "Only participants who stuck with the exercise program for the full 5 years are\n",
    "analyzed. Those who dropped out (likely due to difficulty) are ignored, biasing\n",
    "the results—survivorship bias.\n",
    "\n",
    "\n",
    "**@B9.** A national poll on political views is conducted by sampling only\n",
    "households with landline phones.\n",
    "\n",
    "**Answer**: Exclusion Bias (and possibly Undercoverage Bias)\n",
    "\n",
    "Explanation:\n",
    "Landline owners skew older; younger and lower-income people are excluded. This\n",
    "exclusion leads to biased representation of the true population—exclusion\n",
    "bias and also undercoverage bias.\n",
    "\n",
    "\n",
    "**@B10.** In a clinical drug trial, several participants drop out because of adverse\n",
    "side effects before the trial ends, and are excluded from the final analysis.\n",
    "\n",
    "**Answer**: Attrition Bias\n",
    "\n",
    "Explanation:\n",
    "Participants who experienced adverse side effects drop out, and\n",
    "excluding them changes the apparent safety and effectiveness of the\n",
    "drug. This is a clear example of attrition bias.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98257c75-9773-4404-8b79-771c41ced459",
   "metadata": {},
   "source": [
    "## Part @P:SD. Study Design\n",
    "\n",
    "HEREPOOP\n",
    "\n",
    "**@SD1.** A team is conducting a study on a weight-loss drug. Participants volunteer\n",
    "for the study after seeing a commercial that highlights expected success stories.\n",
    "Identify the primary bias introduced in participant recruitment. Discuss how the\n",
    "study’s validity could be improved through better sampling techniques.\n",
    "\n",
    "**Answer**\n",
    "\n",
    "Self-selection bias.\n",
    "\n",
    "Participants chose to enroll in the study after viewing a commercial.\n",
    "\n",
    " * The ad highlights success stories, which may attract individuals\n",
    "   who are optimistic, more motivated, or more predisposed to succeed.\n",
    "        \n",
    " * These volunteers are not representative of the general population —\n",
    "   especially those who might respond differently to the drug or are\n",
    "   less likely to self-select into such programs.\n",
    "\n",
    " * Impact on Study Validity:\n",
    "   \n",
    "   - External validity is compromised: the results may overestimate the drug’s effectiveness in the general population.\n",
    "\n",
    "   - The findings are likely not generalizable beyond the type of person attracted by the ad.\n",
    "\n",
    "How to Improve:\n",
    "\n",
    "  * Use random sampling from a larger pool of eligible participants\n",
    "    (e.g., medical registries or health system databases).\n",
    "    \n",
    "  * Recruit participants through neutral channels (e.g., primary care\n",
    "    providers), not promotional materials.\n",
    "    \n",
    "  * Ensure recruitment does not emphasize outcomes, but focuses on study\n",
    "    participation and transparency.\n",
    "    \n",
    "    \n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "**@SD2.** In a vaccine trial, participants are told they may receive either a\n",
    "vaccine or a placebo. Some participants in the placebo group still develop antibodies\n",
    "because they mistakenly believe they received the vaccine and modify their behavior\n",
    "accordingly. Identify and explain the phenomenon. How could the researchers redesign\n",
    "the study to minimize this effect?\n",
    "\n",
    "**Answer**:\n",
    "\n",
    "With respect to the antibodies, those in the placebo group believing\n",
    "they have been vaccinated may engage in riskier social behaviors that\n",
    "would tend to increase the probability of becoming infected.  This\n",
    "is a kind of placebo effect.\n",
    "\n",
    "There are many possible answers.   Here are a few:\n",
    "\n",
    "**Behavioral reinforcement**: Provide regular reminders to all participants \n",
    "— regardless of group assignment — that they may have received the\n",
    "placebo and should continue to follow safety precautions. This communication,\n",
    "delivered uniformly, preserves blinding.\n",
    "\n",
    "**Behavior monitoring**: Participants could optionally install an app that\n",
    "passively tracks behavior (e.g., location clustering, time in public \n",
    "places). While this raises privacy concerns, participation in such \n",
    "onitoring could be voluntary, and financially compensated.\n",
    "\n",
    "**Behavioral stratification**: Using data from surveys or app monitoring,\n",
    "participants could be grouped into behavioral cohorts based on exposure\n",
    "risk. While rare behaviors would limit statistical power, this could\n",
    "help control for behavioral confounding in the analysis.\n",
    "\n",
    "**Deterrents for risky behavior**: The trial could include clearly defined\n",
    "behavioral expectations, and participants engaging in highly risky\n",
    "activities (e.g., large unmasked gatherings) might face consequences\n",
    "such as loss of compensation. However, this must be carefully weighed\n",
    "against ethical concerns, as punitive measures may introduce new forms\n",
    "of bias or reduce retention.\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de703a41-468b-4fa4-9237-0b6f55783223",
   "metadata": {},
   "source": [
    "**@SD3.** A study evaluating a new migraine medication fails to detect a real\n",
    "benefit, even though the drug is effective. What type of error has occurred (Type I\n",
    "or Type II)? What could have caused this mistake? Suggest two ways to reduce the\n",
    "risk of this type of error in future studies.\n",
    "\n",
    "**Answers**\n",
    "\n",
    "*What type of error has occurred (Type I\n",
    "or Type II)?*\n",
    "\n",
    "Type II, also known as a false negative.\n",
    "\n",
    "*Explanation*:\n",
    "\n",
    "Imagine that we define the null hypothesis $H_0$ as follows:\n",
    "\n",
    "$H_0$: The migraine medication has no benefit.\n",
    "\n",
    "If we reject the null hypothesis when there is no real benefit, this\n",
    "would be a false discovery, i.e., a false positive, a type I error.\n",
    "\n",
    "If we fail to reject the null hypothesis then we are missing a \n",
    "discovery, i.e., a false negative, a type II error.\n",
    "\n",
    "*What could have cause this mistake?*\n",
    "\n",
    "There could be many different possibilities.\n",
    "\n",
    "* Setting the significance level too low.\n",
    "\n",
    "* Samples sizes may be too small resulting in sampling error dominating the\n",
    "  result.\n",
    "  \n",
    "* Failure in preparing or administering the medication: wrong dosage\n",
    "  or overproviding placebo.\n",
    "\n",
    "* Selection bias may have such as oversampling groups that would naturally\n",
    "  have a resistance to the medication.\n",
    "\n",
    "* Confounding factors may dominate the result, e.g., exposure to\n",
    "  environmental factors may be a much stronger factor than the\n",
    "  medication.\n",
    "\n",
    "* Failure in record keeping: for example mixing up the members in the placebo\n",
    "  and exposed groups.\n",
    "\n",
    "* Sabotage.  A competitor may intentionally manipulate results.\n",
    "\n",
    "*Suggest two ways to reduce the risk of this type of error in future studies.*\n",
    "\n",
    "I provide her more than two even though the question only requires two ways.\n",
    "\n",
    "Reducing sampling error could be accomplished by inceasing sampling size.\n",
    "\n",
    "Record keeping, preparation errors, and administration errors may be \n",
    "mitigated with better training of personnel and better monitoring.\n",
    "Of the latter, video recoring preparation and medicatin administration\n",
    "might catch errors and introduce a deterrent effect if serious\n",
    "mistakes result in personnel dismissal.\n",
    "\n",
    "Selection bias may be reduced by ensuring randomness in the selection\n",
    "process, or by intentionally breaking the respondents into cohorts\n",
    "to better identify possible confounding factors.\n",
    "\n",
    "Behavioral and environmental confounding factors may be identified\n",
    "by introducing monitoring behavior among participants, e.g., using\n",
    "mobile apps that track the participants.\n",
    "\n",
    "The effects of sabotage may be partially mitigated with \n",
    "better vetting of personnel, requiring the personnel to \n",
    "sign statements of conflict of interest, warning that\n",
    "personnel that criminal behavior will be prosecuted\n",
    "or pursued for the maximum civil penalties.\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a779e6c-2305-4ad0-b9f7-b313dd5a83fb",
   "metadata": {},
   "source": [
    "## Part @P:Stats. Statistics\n",
    "\n",
    "Suppose we have the following data:\n",
    "\n",
    "Sample Dataset $T: 5, 12, 7, 3, 8$\n",
    "\n",
    "**@ST1**. Compute the sample standard deviation $s_T$.\n",
    "\n",
    "**Answer**:\n",
    "\n",
    "$[3, 5, 7, 8, 12]$\n",
    "\n",
    "$\\bar{T} = \\frac{1}{5} \\sum_{i=1}^5 x_i = \\frac{1}{5} (3 + 5 + 7 + 8 + 12) = \\frac{1}{5} \\cdot 35 = 7$\n",
    "\n",
    "$\\text{Var}[T] = \\frac{1}{n-1} \\sum_{i=1}^n (T - \\bar{T})^2 = \\frac{1}{4} (4^2 + 2^2 + 0^2 + 1^2 + 5^2) = \\frac{46}{4} = 11.5$\n",
    "\n",
    "$s_T = \\sqrt{Var[T]} = \\sqrt{11.5} \\approx 3.39$\n",
    "\n",
    "mean = 7, variance = 11.5, standard deviation ≈ 3.39 \n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "**@ST2**. Find the range of the sample dataset.\n",
    "\n",
    "**Answer**:\n",
    "\n",
    "12 - 3 = 9 \n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "**@ST3**. Find the median of the sample dataset.\n",
    "\n",
    "**Answer**:\n",
    "\n",
    "7\n",
    "\n",
    "There are an odd number of elements in the set so the middle element\n",
    "is the median.  If there had been an even number then we would average\n",
    "the two samples on either side of the middle.\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "**@ST4**. Find the 25th percentile (Q1) using linear interpolation (if necessary).\n",
    "\n",
    "\n",
    "**Answer**:\n",
    "\n",
    "(3 + 5)/2 = 4\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "**@ST5**. Find the 75th percentile (Q3) using linear interpolation (if necessary).\n",
    "\n",
    "\n",
    "**Answer**:\n",
    "\n",
    "(8 + 12)/2 = 10\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b5276d-0cd2-415a-a3a9-3771c550d5e0",
   "metadata": {},
   "source": [
    "**@ST6**. Find the Interquartile Range (IQR).\n",
    "\n",
    "**Answer**:\n",
    "\n",
    "10 - 4 = 6\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "**@ST7**. Given the following probability density function (PDF) $g(x)$:\n",
    "\n",
    "\n",
    "**Answer**:\n",
    "\n",
    "$$\\begin{cases}\n",
    "3x^2 & \\text{if } 0 \\leq x \\leq 1 \\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}$$\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "**@ST8**. Verify that $g(x)$ in Problem #ST7 is a valid PDF.\n",
    "\n",
    "**Answer**: \n",
    "\n",
    "- $g(x) \\geq 0$ for all $x$.\n",
    "- The area under the pdf is exactly 1.  \n",
    "  \n",
    "$\\int_0^1 3x^2 dx = 3\\left[\\frac{x^3}{3}\\right]_0^1 = (1^3 - 0) = 1$\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "**@ST9**. Compute the mean $\\mu$ of $X$ for $g(x)$ defined in Problem #ST7.\n",
    "\n",
    "**Answer**: \n",
    "\n",
    "$\\mu = \\int_0^1 x \\times 3x^2 dx = 3\\int_0^1 x^3 dx = 3\\left[\\frac{x^4}{4}\\right]_0^1 = 3(1/4) = 0.75$\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "**@ST10**. Compute the variance $\\sigma^2$ and standard deviation $\\sigma$ of $X$.\n",
    "\n",
    "**Answer**:\n",
    "\n",
    "- First compute $E[X^2]$:\n",
    "  \n",
    "$E[X^2] = \\int_0^1 x^2 \\times 3x^2 dx = 3\\int_0^1 x^4 dx = 3\\left[\\frac{x^5}{5}\\right]_0^1 = 3(1/5) = 0.6$\n",
    "\n",
    "- Variance:\n",
    "  \n",
    "$\\sigma^2 = E[X^2] - (\\mu)^2 = 0.6 - (0.75)^2 = 0.6 - 0.5625 = 0.0375$\n",
    "\n",
    "- Standard deviation:\n",
    "  \n",
    "$\\sigma = \\sqrt{0.0375} \\approx 0.194$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61991279-f6b0-47ad-b73c-15317dfdc96e",
   "metadata": {},
   "source": [
    "## Part @P:Skew. Skew\n",
    "\n",
    "**@S1**. Is this skewed, if yes then is it positively or negatively skewed?\n",
    "\n",
    "<img src=\"skew1.png\" width=400>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9b7f84-6806-4d80-8e0b-2084c416fde2",
   "metadata": {},
   "source": [
    "**Answer**:\n",
    "\n",
    "Positive skew.  Follow the tail.\n",
    "```\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787293a8-fd53-40e5-a586-b2129f8c1ba5",
   "metadata": {},
   "source": [
    "**@S2**. Is this skewed, if yes then is it positively or negatively skewed?\n",
    "\n",
    "<img src=\"skew2.jpg\" width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205feeee-cc92-461b-984e-dd38897363e5",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "\n",
    "Negative skew.  Follow the tail.\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cda8e32-bc37-4239-b51a-88471c6658f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "adca7a55-04ab-4e19-b678-58bde14c7d33",
   "metadata": {},
   "source": [
    "## Part @P:Correlation. Correlation\n",
    "\n",
    "State whether the following have positive, negative, or no Pearson correlation.\n",
    "\n",
    "<img src=\"prob_corr.png\" width=\"width:800px;\">\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ac2bbe",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "360324e2-8b9a-44fd-a9bf-1433dba13f2a",
   "metadata": {},
   "source": [
    "**Figure 1:** positive\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "**Figure 2:** negative\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "**Figure 3:** near zero correlation. Possibly slightly negative.\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "**Figure 4:** near zero correlation\n",
    "```\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa07d597-37ea-4b97-9575-33562739696f",
   "metadata": {},
   "source": [
    "## Part @P:Conf. Confidence\n",
    "\n",
    "**@CI1.** The reaction times (in seconds) of a group of athletes are normally\n",
    "distributed with a mean $\\mu = 0.75$ seconds and a standard deviation $\\sigma = 0.1$ seconds.\n",
    "What is the Z-score for an athlete who recorded a reaction time of 0.60 seconds?\n",
    "\n",
    "Answer:\n",
    "\n",
    "$z = \\frac{0.60 - 0.75}{0.1} = \\frac{-0.15}{0.1} = -1.5$\n",
    "\n",
    "$\\boxed{-1.5}$\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b24099",
   "metadata": {},
   "source": [
    "\n",
    "**@CI2.** In a memory experiment, the population mean time to recall a list\n",
    "of words is $\\mu = 45$ seconds with $\\sigma = 8$ seconds.\n",
    "Find the Z-score for a participant who took 55 seconds.\n",
    "\n",
    "Answer:\n",
    "\n",
    "$z = \\frac{55 - 45}{d8} = \\frac{10}{8} = 1.25$\n",
    "\n",
    "$\\boxed{1.25}$\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2946fdb2",
   "metadata": {},
   "source": [
    "\n",
    "**@CI3.** A sample of $n = 150$ light bulbs is tested for lifetime. The sample mean is 1200 hours,\n",
    "and the known population standard deviation is $\\sigma = 100$ hours.\n",
    "Construct a 99% confidence interval for the true mean lifetime of light bulbs.\n",
    "\n",
    "Answer:\n",
    "\n",
    "* Standard Error (SE):\n",
    "\n",
    "$SE = \\frac{\\sigma}{\\sqrt{n}} = \\frac{100}{\\sqrt{150}} \\approx 8.165$\n",
    "\n",
    "\n",
    "* Z for 99% confidence ≈ 2.576\n",
    "\n",
    "* Margin of Error (ME):\n",
    "\n",
    "$ME = 2.576 \\times 8.165 \\approx 21.04$\n",
    "\n",
    "* Confidence Interval:\n",
    "\n",
    "$(1200 - 21.04, 1200 + 21.04) = \\boxed{(1178.96, 1221.04)}$\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6e22e4",
   "metadata": {},
   "source": [
    "\n",
    "**@CI4.** A botanist measures the heights of $n = 20$ sunflowers.\n",
    "The sample mean height is 150 cm, and the sample standard deviation is 12 cm.\n",
    "Construct a 95% confidence interval for the true mean height of sunflowers.\n",
    "\n",
    "Answer:\n",
    "\n",
    "* Standard Error:\n",
    "\n",
    "$SE = \\frac{\\sigma}{\\sqrt{n}} = \\frac{12}{\\sqrt{20}} \\approx 2.683$\n",
    "\n",
    "* t-value for 95% CI with df = 19 ≈ 2.093\n",
    "\n",
    " \n",
    "* Margin of Error:\n",
    "\n",
    "$ME = 2.093 \\times 2.683 \\approx 5.61$\n",
    "\n",
    "* Confidence Interval:\n",
    "\n",
    "(150 - 5.61, 150 + 5.61) = (144.39, 155.61)\n",
    "\n",
    "$\\boxed{(144.39, 155.61)}$\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24307fd8",
   "metadata": {},
   "source": [
    "CI5.** A laboratory measures the cholesterol levels of a random\n",
    "sample of $n = 16$ patients. The sample mean cholesterol level\n",
    "is 190 mg/dL with a sample standard deviation of 25 mg/dL.\n",
    "Construct a 90% confidence interval for the true mean cholesterol level.\n",
    "\n",
    "Answer:\n",
    "\n",
    "* Standard Error:\n",
    "\n",
    "$SE = \\frac{\\sigma}{\\sqrt{n}} = \\frac{25}{\\sqrt{16}} = 6.25$\n",
    "\n",
    "* t-value for 90% CI with df = 15 ≈ 1.753\n",
    "  \n",
    "* Margin of Error:\n",
    "\n",
    "ME = 1.753 \\times 6.25 = 10.956\n",
    "\n",
    "* Confidence Interval:\n",
    "\n",
    "(190 - 10.956, 190 + 10.956) = (179.04, 200.96)\n",
    "\n",
    "$\\boxed{(179.04, 200.96)}$\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "**@CI6.**  A nutritionist collects a sample of $n = 200$ daily\n",
    "calorie intakes from randomly selected adults. The sample mean\n",
    "is 2200 calories, and the population standard deviation is\n",
    "$\\sigma = 300$ calories. Construct a 95% confidence interval\n",
    "for the true mean daily calorie intake.\n",
    "\n",
    "* Standard Error:\n",
    "\n",
    "$SE = \\frac{\\sigma}{\\sqrt{n}} = \\frac{300}{\\sqrt{200}} \\approx 21.21$\n",
    "\n",
    "* Z-value for 95% CI ≈ 1.96\n",
    "  \n",
    "* Margin of Error:\n",
    "\n",
    "$ME = 1.96 \\times 21.21 \\approx 41.57$\n",
    "\n",
    "* Confidence Interval:\n",
    "\n",
    "$(2200 - 41.57, 2200 + 41.57) = \\boxed{(2158.43, 2241.57)}$\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "**@CI7.**  The population mean blood pressure for adults is\n",
    "known to be 120 mmHg with a standard deviation of 15 mmHg.\n",
    "What is the Z-score for an individual with a blood pressure\n",
    "of 145 mmHg?\n",
    "\n",
    "Answer:\n",
    "\n",
    "$z = \\frac{145 - 120}{15} = \\frac{25}{15} = \\boxed{1.6667}$\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "**@XCI8.**  In a standardized math test, the population mean score\n",
    "is $\\mu = 500$ with a standard deviation $\\sigma = 100$.\n",
    "Calculate the Z-score for a student who scores 650.\n",
    "\n",
    "Answer:\n",
    "\n",
    "$z = \\frac{650 - 500}{100} = \\frac{150}{100} = \\boxed{1.5}$\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "**@CI9.** A sample of $n = 30$ laptop batteries is tested.\n",
    "The sample mean battery life is 7.5 hours, with a sample standard\n",
    "deviation of 0.8 hours.  Construct a 95% confidence interval for\n",
    "the mean battery life.\n",
    "\n",
    "* Standard Error:\n",
    "\n",
    "$SE = \\frac{0.8}{\\sqrt{30}} \\approx 0.146$\n",
    "\n",
    "* t-value for 95% CI with df = 29 ≈ 2.045\n",
    " \n",
    "* Margin of Error:\n",
    "\n",
    "$ME = 2.045 \\times 0.146 \\approx 0.299$\n",
    "\n",
    "* Confidence Interval:\n",
    "\n",
    "$(7.5 - 0.299, 7.5 + 0.299) = \\boxed{(7.201, 7.799)}$\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "**@CI10.**  An online retailer’s average shipping time is normally\n",
    "distributed with mean 3 days and standard deviation 0.5 days.\n",
    "Find the Z-score for an order that arrives in 2 days.\n",
    "\n",
    "$z = \\frac{2 - 3}{0.5} = \\frac{-1}{0.5} = \\boxed{-2.0}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466b07a4-bea8-4ce6-ac84-9bd9b145eb04",
   "metadata": {},
   "source": [
    "## Part @P:Hyp. Hypothesis Testing\n",
    "\n",
    "A company is testing whether a new employee training program (Program B) improves productivity compared to the current training program (Program A). Productivity is measured as the number of tasks completed correctly in a standardized evaluation.\n",
    "\n",
    "In the trial, there are 50 employees divided into two groups:\n",
    "\n",
    "* Group A: 25 employees trained with Program A.\n",
    "* Group B: 25 employees trained with Program B.\n",
    "\n",
    "We collected the results shown in Table #P:Hyp.\n",
    "\n",
    "<center>\n",
    "Table #P:Hyp. Employee Productivity Scores by Training Program\n",
    "</center>\n",
    "\n",
    "Group  | mean  | standard deviation |\n",
    "-------|-------|--------------------|\n",
    "A      | 82    |  6                 |\n",
    "B      | 88    |  7                 |\n",
    "\n",
    "Let:\n",
    "\n",
    "* $\\bar{x}_A$ = mean score for Group A\n",
    "* $\\bar{x}_B$ = mean score for Group B\n",
    "* $s_A$ = standard deviation of scores for Group A\n",
    "* $s_B$ = standard deviation of scores for Group B\n",
    "* $n_A$ = number of employees in Group A\n",
    "* $n_B$ = number of employees in Group B\n",
    "\n",
    "The significance level is $\\alpha = 0.05$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81371aab-144b-4c8f-be10-1774f407bce2",
   "metadata": {},
   "source": [
    "**@Hyp1**. State the null hypothesis $(H_0)$ for this problem.\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "$H_0$: The mean score is the same for programs $A$ and $B$.\n",
    "\n",
    "Or more concisely stated,\n",
    "\n",
    "$H_0: \\mu_A = \\mu_B$\n",
    "\n",
    "Not that $\\mu$ is used to distinguish between the sample means and the mean\n",
    "of the underlying distributions for $A$ and $B$.\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "**@Hyp2**. State the alternative hypothesis $(H_1)$ for this problem.\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "$H_A: \\mu_A \\neq \\mu_B$\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693f32ef-7ffb-4795-9edd-25a5f0dfcee2",
   "metadata": {},
   "source": [
    "**@Hyp3**. Calculate the pooled variance $s_p^2$ based on $s_A$, $s_B$, $n_A$, and $n_B$.\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "$s_p^2 = \\frac{(n_A - 1)s_A^2 + (n_B - 1)s_B^2}{n_A + n_B - 2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2819bc3b-a5aa-4cbf-9494-fc38ce1dd118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "pooled variance $s_p^2=42.500$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_A = 25\n",
    "s_A = 6\n",
    "n_B = 25\n",
    "s_B = 7\n",
    "\n",
    "s_p_sq = ((n_A-1)*s_A**2 + (n_B-1)*s_B**2)/(n_A + n_B -2)\n",
    "\n",
    "from IPython.display import display, Latex\n",
    "\n",
    "display(Latex(f\"pooled variance $s_p^2={s_p_sq:.3f}$\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d324b50c-c97d-4af9-ba80-142beb3b3f28",
   "metadata": {},
   "source": [
    "**@Hyp4**. Should we use the t-distribution or the Gaussian (normal) distribution for this hypothesis test?\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "We should use the t-distribution.\n",
    "\n",
    "Although each group has 25 samples — close to the commonly cited threshold of 30 — \n",
    "the rule of thumb is that if the sample size is less than 30 and the population\n",
    "standard deviation is unknown, we should use the t-distribution, especially when\n",
    "the underlying population shape is not known to be normal.\n",
    "\n",
    "In this case:\n",
    "\n",
    " * The problem provides only sample standard deviations, not population.\n",
    "\n",
    " * No information is given about the shape of the underlying distributions.\n",
    "\n",
    " * Therefore, the conditions for safely using the Gaussian (z) distribution are not met.\n",
    "\n",
    " * Moreover, even with moderate sample sizes, the t-distribution is more\n",
    "   conservative, which helps reduce the risk of Type I errors (false positives).\n",
    "\n",
    "Also worth noting:\n",
    "\n",
    " * If the population were highly skewed or had infinite variance, the\n",
    "   Central Limit Theorem would not apply, and neither the t nor normal\n",
    "   approximation would be valid.\n",
    "   \n",
    " * But since the only data available are sample means and standard\n",
    "   deviations, and no obvious violations are noted, the t-distribution\n",
    "   is the safest choice for inference.\n",
    " \n",
    "```\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d5b5d8-792a-497b-bf90-83b15e4c692f",
   "metadata": {},
   "source": [
    "**@Hyp5**.  Calculate the test statistic.\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "Sine we are going to compute the t-distribution we\n",
    "compute the t test statistic.\n",
    "\n",
    "We can restate the null hypothesis as \n",
    "\n",
    "$H_0: \\mu_A - \\mu_B = 0$\n",
    "\n",
    "We are thus characterizing the variable \n",
    "\n",
    "$D = \\bar{x}_A - \\bar{x}_B$\n",
    "\n",
    "We ask the question what is the probability that $D$ is as\n",
    "or more extreme than the observed difference $\\bar{x}_A - \\bar{x}_B$.\n",
    "\n",
    "The t-statistic is the \n",
    "\n",
    "$t = \\frac{|\\bar{x}_A - \\bar{x}_B|}{SE}$\n",
    "\n",
    "$\\text{Standard Error (SE)} = s_p \\cdot \\sqrt{\\frac{1}{n_A} + \\frac{1}{n_B}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41628e67-f7bc-47b9-95d1-5ea7f61996f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "SE $= 1.844$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$t \\approx 3.254$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from math import sqrt\n",
    "\n",
    "s_p = sqrt(s_p_sq)\n",
    "SE = s_p * sqrt(1 / n_A + 1 / n_B)\n",
    "display(Latex(f\"SE $= {SE:.3f}$\")) \n",
    "t_stat = (88-82)/ SE\n",
    "display(Latex(r\"$t \\approx \" + f\"{t_stat:.3f}$\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e789b249-ac18-4ba3-b286-8cfc54c9268d",
   "metadata": {},
   "source": [
    "**@Hyp6**. Calculate the p-value.\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "We plug the t value into a two-tailed t-test.   We are interested\n",
    "in the probablity that we would see $D$ that is equal or more extreme\n",
    "than $t$ in either direction.\n",
    "\n",
    "Let $F_t(t; \\nu)$ denote the CDF of the t-distribution with $\\nu$ \n",
    "degrees of freedom.\n",
    "\n",
    "$P(|D| \\geq t) = 2(1-P(D < t) = 2(1-F_t(t;\\nu))$\n",
    "\n",
    "To compute $\\nu$ we have $n_A-1$ degreees of freedom from group $A$ and\n",
    "$n_B-1$ degrees of freedom from group $B$ and thus \n",
    "\n",
    "$\\nu = (n_A-1) + (n_B-1) = n_A + n_B - 2$\n",
    "\n",
    "So,\n",
    "\n",
    "$p = P(|D| \\geq t) = 2(1-F_t(t; n_A + n_B - 2))$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e067a12-5eee-4ae8-80d6-d0395de0dfce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "The p-value is 0.00209"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.stats import t\n",
    "dof = n_A + n_B - 2    # nu = dof = degrees of freedom\n",
    "p = 2*(1-t.cdf(t_stat, dof))\n",
    "display(Latex(f\"The p-value is {p:.5f}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba2deb0-8e2b-4490-b8a5-bc52cf24d644",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "**@Hyp7**. Do we reject the null hypothesis, and what does that imply about the effectiveness of the new training program?\n",
    "\n",
    "\n",
    "Answer:\n",
    "\n",
    "With a p-value of $0.00209$, this is well below the significant level of 0.05, and thus we reject the null hypothesis.\n",
    "```\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c918ee7e-7ff2-4bd9-b62d-03b99199e706",
   "metadata": {},
   "source": [
    "## Part @P:Perm. Parametric vs. Permutation Testing\n",
    "\n",
    "* In traditional hypothesis testing, we often assume that the\n",
    "  sampling distribution of $\\bar{A} - \\bar{B}$ is approximately Gaussian,\n",
    "  based on the Central Limit Theorem (CLT).\n",
    "\n",
    "* In permutation tests, we do not assume a parametric form; instead,\n",
    "  we generate an empirical distribution of $\\bar{X} - \\bar{Y}$ by randomly\n",
    "  partitioning the combined data many times.\n",
    "\n",
    "While the CLT justifies Gaussian approximations in many settings, it is a\n",
    "limiting result: it holds as the number of independent random variables\n",
    "grows large, and under the condition that those variables have finite\n",
    "mean and variance.\n",
    "\n",
    "However, for small sample sizes or when the underlying data is highly\n",
    "skewed or has heavy tails, the Gaussian approximation can be poor.\n",
    "In such cases, and especially when computational resources are\n",
    "available, permutation testing offers a more reliable, assumption-free\n",
    "alternative by constructing the sampling distribution empirically.\n",
    "\n",
    "**@PP0**  A product manager is testing two versions of a mobile app landing\n",
    "page to see if version A or version B leads to higher user engagement\n",
    "time (in minutes). A random sample of users is split into two groups of\n",
    "equal size, and their session durations are recorded.\n",
    "\n",
    "The observed data is:\n",
    "\n",
    "**Group A**\n",
    "\n",
    "$$[4.5, 5.0, 3.8, 4.2, 4.9, 5.1, 3.7, 4.8]$$\n",
    "\n",
    "**Group B**\n",
    "\n",
    "$$[5.2, 5.5, 5.1, 4.9, 5.6, 5.3, 5.0, 5.4]$$\n",
    "\n",
    "* (a) State the null and alternative hypotheses.\n",
    "\n",
    "**Answer**:\n",
    "\n",
    "variable  |  meaning                                         |\n",
    "----------|--------------------------------------------------|\n",
    "$\\bar{A}$ | average engagement time in group $A$ in minutes. |\n",
    "$\\bar{B}$ | average engagement itme in group $B$ in minutes. |\n",
    "\n",
    "\n",
    "$H_0:$ groups $A$ and $B$ have equal user engagement.\n",
    "\n",
    "or equivalently\n",
    "\n",
    "$H_0: $\\bar{A} = \\bar{B}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5cad4c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "* (b) Compute the observed difference in sample means: $\\bar{B} - \\bar{A}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "93bc440f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\bar{A} = 4.500$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\bar{B} = 5.250$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$|\\bar{B} - \\bar{A}| = 0.750$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "A = np.array([4.5, 5.0, 3.8, 4.2, 4.9, 5.1, 3.7, 4.8])\n",
    "B = np.array([5.2, 5.5, 5.1, 4.9, 5.6, 5.3, 5.0, 5.4])\n",
    "bar_A = np.mean(A)\n",
    "bar_B = np.mean(B)\n",
    "D_orig = abs(bar_B - bar_A)\n",
    "\n",
    "display(Latex(f\"$\\\\bar{{A}} = {bar_A:.3f}$\"))\n",
    "display(Latex(f\"$\\\\bar{{B}} = {bar_B:.3f}$\"))\n",
    "display(Latex(f\"$|\\\\bar{{B}} - \\\\bar{{A}}| = {D_orig:.3f}$\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d611db97",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "* (c) Write Python code to perform a permutation test.  The code should do the following:\n",
    "\n",
    "  - Combine the two samples into a single dataset.\n",
    "   \n",
    "  - Randomly shuffle the combined dataset and partition it into\n",
    "    two groups of equal size (8 each).\n",
    "   \n",
    "  - Compute the difference in means between the two new groups.\n",
    "\n",
    "  - Repeat this process 1000 times to generate an empirical distribution\n",
    "    of the difference in means under the null hypothesis.\n",
    "\n",
    "**Answer:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0b9ea63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.5, 5.0, 3.8, 4.2, 4.9, 5.1, 3.7, 4.8, 5.2, 5.5, 5.1, 4.9, 5.6, 5.3, 5.0, 5.4]\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$C = [4.5,5.0,3.8,4.2,4.9,5.1,3.7,4.8,5.2,5.5,5.1,4.9,5.6,5.3,5.0,5.4]$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from numpy.random import shuffle\n",
    "C = np.append(A, B)\n",
    "print(list(C))\n",
    "Cstr = \",\".join(str(c) for c in C)\n",
    "display(Latex(f\"$C = [{Cstr}]$\"))  # prettier way.\n",
    "D = []\n",
    "for i in range(1000):\n",
    "    # shuffle the data\n",
    "    shuffle(C)\n",
    "    A = C[:len(A)]\n",
    "    B = C[len(A):]\n",
    "    bar_A = np.mean(A)\n",
    "    bar_B = np.mean(B)\n",
    "    D.append(abs(bar_B - bar_A))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4991e9fe",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "* (c) Write code to calculucate the empirical p-value:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "330b39b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "The empirical p-value is 0.00500"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "p_value = np.mean(np.abs(D) >= D_orig)\n",
    "\n",
    "display(Latex(f\"The empirical p-value is {p_value:.5f}\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13192228",
   "metadata": {},
   "source": [
    "* (d) Based on the p-value and a significance level of $\\alpha = 0.05$, can you reject\n",
    "  the null hypothesis?\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "The p-value of 0.005 is less than the significance level $\\alpha=0.05$, thus we can \n",
    "reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9006ee-418e-40da-98b0-8657f2b93e11",
   "metadata": {},
   "source": [
    "## Part @P:ANOVA. Permutation ANOVA Problems\n",
    "\n",
    "### Problem @P1: Plant Growth Experiment\n",
    "\n",
    "A researcher tests whether 3 different fertilizers affect plant growth. She randomly assigns 5 plants to each group and measures height (in cm) after 6 weeks.\n",
    "\n",
    "| Fertilizer A | Fertilizer B | Fertilizer C |\n",
    "|--------------|--------------|--------------|\n",
    "| 10.1         | 13.3         | 12.0         |\n",
    "| 9.8          | 14.1         | 11.5         |\n",
    "| 10.5         | 12.7         | 11.9         |\n",
    "| 9.9          | 13.5         | 12.2         |\n",
    "| 10.3         | 14.0         | 11.7         |\n",
    "\n",
    "**Task:**\n",
    "\n",
    "a) State the null hypothesis.\n",
    "b) Write code for  **permutation-based ANOVA** to test whether the mean height differs across fertilizers.\n",
    "c) Use 1000 permutations.\n",
    "d) Report the empirical p-value.\n",
    "e) Decide whether we should reject the null hypothesis when using a confidence level fo $\\alpha=0.01$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761a0f0c-7f50-48a1-be8f-29c9f44a888e",
   "metadata": {},
   "source": [
    "a) State the null hypotehsis\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "$H_0$: the three fertilizers result have the same mean effect on plant growth.\n",
    "\n",
    "Or restated mathematically as \n",
    "\n",
    "$H_0: \\mu_A = \\mu_B = \\mu_C$\n",
    "\n",
    "We use $\\mu$ to denote that our null hypothesis states that the underlying\n",
    "distribution means are equal.   The sample means for any given sample may not\n",
    "be equal.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f8f316",
   "metadata": {},
   "source": [
    "b) Write code for **permutation-based ANOVA** to test the null hypothesis.\n",
    "c) Use 1000 permutations.\n",
    "d) Report the empirical p-value.\n",
    "\n",
    "**Answer**\n",
    "\n",
    "We do parts b-d below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fcbda2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_statistic(df):\n",
    "\n",
    "    # Step 1: mean across all values in a column is the same as \n",
    "    # taking the mean of all samples pooled together.\n",
    "    grand_mean = df['Measurement'].mean()\n",
    "\n",
    "    # Break up the table by rows that have the same page number.\n",
    "    groups = df.groupby('Fertilizer')\n",
    "\n",
    "    # Step 3 compute means for each new group.  group['Time'].mean()\n",
    "    # Step 4 compute sum of squares between groups SSB\n",
    "    ss_between = sum(\n",
    "        len(group) * (group['Measurement'].mean() - grand_mean)**2\n",
    "        for _, group in groups\n",
    "    )\n",
    "\n",
    "    # Step 5 SSW\n",
    "    ss_within = sum(\n",
    "        ((group['Measurement'] - group['Measurement'].mean())**2).sum()\n",
    "        for _, group in groups\n",
    "    )\n",
    "\n",
    "    # Step 5 compute MSB, MSW\n",
    "    df_between = groups.ngroups - 1\n",
    "    ms_between = ss_between / df_between\n",
    "\n",
    "    df_within = len(df) - groups.ngroups\n",
    "    ms_within = ss_within / df_within\n",
    "\n",
    "    return ms_between / ms_within"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "02482bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fertilizer A</th>\n",
       "      <th>Fertilizer B</th>\n",
       "      <th>Fertilizer C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1</td>\n",
       "      <td>13.3</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.8</td>\n",
       "      <td>14.1</td>\n",
       "      <td>11.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.5</td>\n",
       "      <td>12.7</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.9</td>\n",
       "      <td>13.5</td>\n",
       "      <td>12.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.3</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fertilizer A  Fertilizer B  Fertilizer C\n",
       "0          10.1          13.3          12.0\n",
       "1           9.8          14.1          11.5\n",
       "2          10.5          12.7          11.9\n",
       "3           9.9          13.5          12.2\n",
       "4          10.3          14.0          11.7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fertilizer</th>\n",
       "      <th>Measurement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fertilizer A</td>\n",
       "      <td>10.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fertilizer A</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fertilizer A</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fertilizer A</td>\n",
       "      <td>9.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fertilizer A</td>\n",
       "      <td>10.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fertilizer B</td>\n",
       "      <td>13.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fertilizer B</td>\n",
       "      <td>14.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Fertilizer B</td>\n",
       "      <td>12.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Fertilizer B</td>\n",
       "      <td>13.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fertilizer B</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Fertilizer C</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Fertilizer C</td>\n",
       "      <td>11.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Fertilizer C</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Fertilizer C</td>\n",
       "      <td>12.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Fertilizer C</td>\n",
       "      <td>11.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Fertilizer  Measurement\n",
       "0   Fertilizer A         10.1\n",
       "1   Fertilizer A          9.8\n",
       "2   Fertilizer A         10.5\n",
       "3   Fertilizer A          9.9\n",
       "4   Fertilizer A         10.3\n",
       "5   Fertilizer B         13.3\n",
       "6   Fertilizer B         14.1\n",
       "7   Fertilizer B         12.7\n",
       "8   Fertilizer B         13.5\n",
       "9   Fertilizer B         14.0\n",
       "10  Fertilizer C         12.0\n",
       "11  Fertilizer C         11.5\n",
       "12  Fertilizer C         11.9\n",
       "13  Fertilizer C         12.2\n",
       "14  Fertilizer C         11.7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observer f-statistic: 90.89727463312371\n",
      "Permutation p-value: 1e-05\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "np.random.seed(62315519)\n",
    "\n",
    "# Data for the DataFrame\n",
    "data = {\n",
    "    'Fertilizer A': [10.1, 9.8, 10.5, 9.9, 10.3],\n",
    "    'Fertilizer B': [13.3, 14.1, 12.7, 13.5, 14.0],\n",
    "    'Fertilizer C': [12.0, 11.5, 11.9, 12.2, 11.7]\n",
    "}\n",
    "\n",
    "# Create the DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "display(df)\n",
    "\n",
    "melted = df.melt(var_name='Fertilizer', value_name='Measurement')\n",
    "display(melted)\n",
    "\n",
    "# Compute the observed F-statistic\n",
    "f_obs = f_statistic(melted)\n",
    "print(\"observer f-statistic:\", f_obs)\n",
    "\n",
    "def perm_test(df):\n",
    "    df = df.copy()\n",
    "    # 2 Shuffle and partition into new groups of the same sizes as the original groups.\n",
    "    df['Measurement'] = np.random.permutation(df['Measurement'].values)\n",
    "    return f_statistic(df)\n",
    "\n",
    "perm_f_values = [perm_test(melted) for _ in range(100000)]\n",
    "\n",
    "# The +1 in the numerator and denominator avoid exactly 0 p-values.\n",
    "#p_value = (np.sum(perm_f_values >= f_obs) + 1) / (len(perm_f_values) + 1)\n",
    "\n",
    "\n",
    "p_value = np.mean([f >= f_obs for f in perm_f_values])\n",
    "\n",
    "print(\"Permutation p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360fbdc7",
   "metadata": {},
   "source": [
    "e) Decide whether we should reject the null hypothesis when using a confidence level fo $\\alpha=0.01$.\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "I received a p-value of 0 for 1000 permutations.  I increased the numberof permutations to\n",
    "100,000 and reran the test, and I added a +1 to the numerator and the denominator to prevent\n",
    "an exactly 0 p-value.   The +1 in the numerator and denominator resulted in a p-value of 1.999e-5. \n",
    "I repeated the exerecise with 10000 permutations without the +1 in the numerator and the denominator\n",
    "and receivd a p-value of 1e-05.   With all three methods, the p-value is far below the \n",
    "confidence level $\\alpha=0.001$, and thus we should reject the null hypothesis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f42ade4-c2bf-4be9-92c1-df90814b0f3a",
   "metadata": {},
   "source": [
    "## Part @P:Chi Chi-Squared Tests\n",
    "\n",
    "A candy company claims that their assorted fruit candies are distributed evenly among five flavors: cherry, orange, lemon, lime, and grape. That is, each flavor should make up exactly 20% of the candies.\n",
    "\n",
    "<center>\n",
    "  Table #P:Chi: Observed Counts of Fruit Candies\n",
    "</center>\n",
    "\n",
    "Flavor  | Observed Counts |\n",
    "--------|-----------------|\n",
    "Cherry  | 45              |\n",
    "Orange  | 35              |\n",
    "Lemon   | 40              |\n",
    "Lime    | 30              |\n",
    "Grape   | 50              |\n",
    "\n",
    "We want to test whether the observed distribution matches the company’s claim.\n",
    "\n",
    "Let:\n",
    " * $O_i$ = observed count for category $i$\n",
    " * $E_i$ = expected count for category $i$\n",
    "\n",
    "We will use a significance level of $\\alpha = 0.05$.\n",
    "\n",
    "**@Chi1**. State the null hypothesis $H_0$ and alternative hypothesis $H_1$.\n",
    "\n",
    "Answer:\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "**@Chi2**. Calculate the expected count $E_i$ for each flavor.\n",
    "\n",
    "Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83168ed1-992f-4cab-9a23-66a8e508399b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp=40.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.25"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 45+35+40+30+50\n",
    "nflavors = 5\n",
    "exp = n / nflavors\n",
    "print(f\"exp={exp}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb45a38-7635-40b7-9595-9ef819ca8f05",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "**@Chi3**. Calculate the value of the Chi-squared test statistic $\\chi^2$.\n",
    "Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c2e1c6-3351-46c5-a2e9-906ca11bd61e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.25"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(25+25+100+100)/40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9615622b-7057-43f5-b8ec-219d991d75df",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "**@Chi4**. Determine the degrees of freedom for the test.\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "There are 5 categories but given we know the number of samples total, the outcomes for the 5th category\n",
    "becomes a function of the other four and thus we have 4 degrees of freedom.\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "**@Chi5**. Find the p-value using the Chi-squared distribution.\n",
    "\n",
    "**Answer:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffefeae-0bfe-4430-b7aa-748e44f59dbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1812398511965556"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import chi2\n",
    "\n",
    "(1-chi2.cdf(6.25, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e7603d-f2eb-4c56-93ce-63b05a0a13c7",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "**@Chi6**. Based on the p-value and the significance level $\\alpha=0.05$, \n",
    "do we reject the null hypothesis? What does this imply about the company’s claim?\n",
    "\n",
    "Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee85e6a-b961-45b3-821d-71e5fac8287d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08271954171409539"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import chi2\n",
    "alpha = 0.05\n",
    "dof = 4\n",
    "chi2.cdf(1-alpha, dof)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "64323f4b-c44f-4115-b123-c8e1c9879c22",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "```\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
